# ç•™å­¦æ¡ˆä¾‹åº“æŠ“å–å·¥å…· Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** æ„å»ºä¸€ä¸ª Python å·¥å…·ï¼Œä»æŒ‡å—è€…ç•™å­¦æ¡ˆä¾‹åº“ (m.compassedu.hk/offer/) æŠ“å–ç•™å­¦å½•å–æ¡ˆä¾‹æ•°æ®ï¼Œæ”¯æŒå¢é‡æ›´æ–°å’Œæ•°æ®å¯¼å‡ºã€‚

**Architecture:** ä½¿ç”¨ Playwright æŠ“å–åŠ¨æ€æ¸²æŸ“çš„é¡µé¢å†…å®¹ï¼Œè§£ææ¡ˆä¾‹å¡ç‰‡æ•°æ®ï¼Œå­˜å‚¨ä¸º JSON/CSV æ ¼å¼ï¼Œæ”¯æŒå¢é‡æŠ“å–ï¼ˆè·³è¿‡å·²æŠ“å–çš„æ¡ˆä¾‹ï¼‰ã€‚

**Tech Stack:** Python 3.10+, Playwright (æµè§ˆå™¨è‡ªåŠ¨åŒ–), pandas (æ•°æ®å¤„ç†), pytest (æµ‹è¯•)

---

## Task 1: åˆ›å»ºé¡¹ç›®ç»“æ„å’Œä¾èµ–é…ç½®

**Files:**
- Create: `compassedu-scraper/README.md`
- Create: `compassedu-scraper/requirements.txt`
- Create: `compassedu-scraper/.gitignore`
- Create: `compassedu-scraper/src/__init__.py`
- Create: `compassedu-scraper/data/.gitkeep`
- Create: `compassedu-scraper/tests/__init__.py`

**Step 1: åˆ›å»ºé¡¹ç›® README**

```markdown
# æŒ‡å—è€…ç•™å­¦æ¡ˆä¾‹åº“æŠ“å–å·¥å…·

ä» m.compassedu.hk/offer/ æŠ“å–ç•™å­¦å½•å–æ¡ˆä¾‹æ•°æ®ã€‚

## åŠŸèƒ½
- æŠ“å–æ¡ˆä¾‹åˆ—è¡¨ï¼ˆå­¦ç”ŸèƒŒæ™¯ã€å½•å–å­¦æ ¡/ä¸“ä¸šã€GPAã€è¯­è¨€æˆç»©ç­‰ï¼‰
- å¢é‡æ›´æ–°ï¼ˆè·³è¿‡å·²æŠ“å–çš„æ¡ˆä¾‹ï¼‰
- å¯¼å‡ºä¸º JSON/CSV æ ¼å¼

## å®‰è£…
```bash
pip install -r requirements.txt
playwright install chromium
```

## ä½¿ç”¨
```bash
python -m src.scraper
```
```

**Step 2: åˆ›å»º requirements.txt**

```txt
playwright==1.48.0
pandas==2.2.0
pytest==8.0.0
pytest-asyncio==0.23.0
```

**Step 3: åˆ›å»º .gitignore**

```
*.pyc
__pycache__/
playwright-report/
test-results/
data/*.json
data/*.csv
```

**Step 4: åˆå§‹åŒ– Python åŒ…æ–‡ä»¶**

åˆ›å»ºç©ºçš„ `__init__.py` æ–‡ä»¶ï¼ˆä¸Šé¢å·²åˆ—å‡ºï¼‰å’Œç©ºçš„ `data/.gitkeep`ã€‚

**Step 5: åˆå§‹åŒ– git ä»“åº“**

```bash
cd compassedu-scraper
git init
git add .
git commit -m "chore: initialize project structure"
```

---

## Task 2: å®ç°æ•°æ®æ¨¡å‹

**Files:**
- Create: `compassedu-scraper/src/models.py`
- Test: `compassedu-scraper/tests/test_models.py`

**Step 1: ç¼–å†™å¤±è´¥çš„æµ‹è¯•**

```python
# tests/test_models.py
from src.models import Case, CaseList

def test_case_creation():
    case = Case(
        university="æ–°åŠ å¡å›½ç«‹å¤§å­¦",
        major="æ™ºèƒ½äº§ä¸šä¸æ•°å­—åŒ–è½¬å‹ç†å­¦ç¡•å£«",
        student_background="å‰æ—å¤§å­¦ ç‰©æµç®¡ç† åº”å±Šç”Ÿ",
        gpa="84.95",
        ielts="6.5",
        toefl=None,
        undergraduate_type="985é™¢æ ¡",
        offer_date="2026å¹´02æœˆ"
    )
    assert case.university == "æ–°åŠ å¡å›½ç«‹å¤§å­¦"
    assert case.major == "æ™ºèƒ½äº§ä¸šä¸æ•°å­—åŒ–è½¬å‹ç†å­¦ç¡•å£«"
    assert case.gpa == "84.95"

def test_case_to_dict():
    case = Case(
        university="ä¸œåŒ—å¤§å­¦ï¼ˆç¾å›½ï¼‰",
        major="åˆ†æå­¦ç¡•å£«",
        student_background="æµ·å¤–æœ¬ç§‘",
        gpa="2.78",
        ielts=None,
        toefl=None,
        undergraduate_type="æµ·å¤–æœ¬ç§‘",
        offer_date="2026å¹´02æœˆ"
    )
    data = case.to_dict()
    assert data["university"] == "ä¸œåŒ—å¤§å­¦ï¼ˆç¾å›½ï¼‰"
    assert data["gpa"] == "2.78"
    assert "ielts" not in data or data["ielats"] is None

def test_case_list_add():
    case_list = CaseList()
    case = Case(
        university="é¦™æ¸¯ä¸­æ–‡å¤§å­¦",
        major="æœºå™¨äººå­¦ç¡•å£«",
        student_background="æ±•å¤´å¤§å­¦ æœºæ¢°è®¾è®¡",
        gpa="85",
        ielts="6.5",
        toefl=None,
        undergraduate_type="æ™®é€šæœ¬ç§‘",
        offer_date="2026å¹´02æœˆ"
    )
    case_list.add(case)
    assert len(case_list.cases) == 1
```

**Step 2: è¿è¡Œæµ‹è¯•éªŒè¯å¤±è´¥**

```bash
cd compassedu-scraper
pytest tests/test_models.py -v
```
Expected: FAIL - ModuleNotFoundError

**Step 3: å®ç°æ•°æ®æ¨¡å‹**

```python
# src/models.py
from dataclasses import dataclass, field
from typing import Optional, List
from datetime import datetime

@dataclass
class Case:
    """å•ä¸ªç•™å­¦æ¡ˆä¾‹æ•°æ®"""
    university: str          # å½•å–å­¦æ ¡
    major: str               # å½•å–ä¸“ä¸š
    student_background: str  # å­¦ç”ŸèƒŒæ™¯ï¼ˆæœ¬ç§‘å­¦æ ¡+ä¸“ä¸š+æ¯•ä¸šçŠ¶æ€ï¼‰
    gpa: str                 # GPA
    ielts: Optional[str] = None    # é›…æ€æˆç»©
    toefl: Optional[str] = None    # æ‰˜ç¦æˆç»©
    gre: Optional[str] = None      # GREæˆç»©
    undergraduate_type: str = ""   # æœ¬ç§‘é™¢æ ¡ç±»å‹ï¼ˆ985/211/æ™®é€šæœ¬ç§‘/æµ·å¤–æœ¬ç§‘ï¼‰
    offer_date: str = ""           # å½•å–æ—¶é—´
    scraped_at: str = field(default_factory=lambda: datetime.now().isoformat())

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼Œè¿‡æ»¤ç©ºå€¼"""
        data = {
            "university": self.university,
            "major": self.major,
            "student_background": self.student_background,
            "gpa": self.gpa,
            "undergraduate_type": self.undergraduate_type,
            "offer_date": self.offer_date,
            "scraped_at": self.scraped_at
        }
        if self.ielts:
            data["ielats"] = self.ielts
        if self.toefl:
            data["toefl"] = self.toefl
        if self.gre:
            data["gre"] = self.gre
        return data


@dataclass
class CaseList:
    """æ¡ˆä¾‹åˆ—è¡¨"""
    cases: List[Case] = field(default_factory=list)

    def add(self, case: Case) -> None:
        self.cases.append(case)

    def to_dicts(self) -> List[dict]:
        return [case.to_dict() for case in self.cases]

    def __len__(self) -> int:
        return len(self.cases)
```

**Step 4: è¿è¡Œæµ‹è¯•éªŒè¯é€šè¿‡**

```bash
pytest tests/test_models.py -v
```
Expected: PASS

**Step 5: æäº¤**

```bash
git add src/models.py tests/test_models.py
git commit -m "feat: add Case and CaseList data models"
```

---

## Task 3: å®ç° Playwright é¡µé¢æŠ“å–å™¨

**Files:**
- Create: `compassedu-scraper/src/scraper.py`
- Test: `compassedu-scraper/tests/test_scraper.py`

**Step 1: ç¼–å†™å¤±è´¥çš„æµ‹è¯•**

```python
# tests/test_scraper.py
import pytest
from src.scraper import CompassEduscraper

@pytest.mark.asyncio
async def test_scraper_initialization():
    scraper = CompassEduscraper(headless=True)
    assert scraper.base_url == "https://m.compassedu.hk/offer/"
    await scraper.close()

@pytest.mark.asyncio
async def test_fetch_cases():
    scraper = CompassEduscraper(headless=True)
    cases = await scraper.fetch_cases(max_cases=5)
    assert len(cases) > 0
    assert len(cases) <= 5

    first_case = cases.cases[0]
    assert first_case.university
    assert first_case.major
    assert first_case.gpa

    await scraper.close()
```

**Step 2: è¿è¡Œæµ‹è¯•éªŒè¯å¤±è´¥**

```bash
pytest tests/test_scraper.py -v
```
Expected: FAIL - ModuleNotFoundError

**Step 3: å®ç°æŠ“å–å™¨æ ¸å¿ƒé€»è¾‘**

```python
# src/scraper.py
import re
from playwright.async_api import async_playwright, Page, Browser
from .models import Case, CaseList


class CompassEduscraper:
    """æŒ‡å—è€…ç•™å­¦æ¡ˆä¾‹åº“æŠ“å–å™¨"""

    BASE_URL = "https://m.compassedu.hk/offer/"

    def __init__(self, headless: bool = True):
        self.headless = headless
        self.browser: Browser = None
        self.page: Page = None

    async def _parse_case_from_card(self, card_element) -> Case | None:
        """ä»æ¡ˆä¾‹å¡ç‰‡å…ƒç´ è§£ææ•°æ®"""
        try:
            # è·å–å¡ç‰‡æ–‡æœ¬å†…å®¹
            text = await card_element.inner_text()

            # æå–å¤§å­¦å’Œä¸“ä¸šï¼ˆæ ¼å¼ï¼šXXå¤§å­¦XXä¸“ä¸šç¡•å£«ç ”ç©¶ç”Ÿofferä¸€æšï¼‰
            title_match = re.search(r'(.*?)ï¼ˆ.*?ï¼‰(.*?)(ç¡•å£«ç ”ç©¶ç”Ÿ|åšå£«ç ”ç©¶ç”Ÿ)offerä¸€æš', text)
            if not title_match:
                return None

            university = title_match.group(1).strip()
            major = title_match.group(2).strip() + title_match.group(3)

            # æå–å­¦ç”ŸèƒŒæ™¯å’ŒGPAï¼ˆæ ¼å¼ï¼šXXå¤§å­¦ XXä¸“ä¸š åº”å±Šç”Ÿ/å…¶ä»–ï¼ŒGPA X.XXï¼‰
            background_match = re.search(r'(.*?) (.*?) (.*?)ï¼ŒGPA([\d.]+)', text)
            if background_match:
                bg_university = background_match.group(1).strip()
                bg_major = background_match.group(2).strip()
                status = background_match.group(3).strip()
                gpa = background_match.group(4)
                student_background = f"{bg_university} {bg_major} {status}"
            else:
                student_background = ""
                gpa = ""

            # æå–é›…æ€æˆç»©
            ielts_match = re.search(r'é›…æ€([\d.]+)', text)
            ielts = ielts_match.group(1) if ielts_match else None

            # æå–æ‰˜ç¦æˆç»©
            toefl_match = re.search(r'æ‰˜ç¦([\d.]+)', text)
            toefl = toefl_match.group(1) if toefl_match else None

            # æå–æœ¬ç§‘ç±»å‹
            undergraduate_type = "æ™®é€šæœ¬ç§‘"  # é»˜è®¤
            if "985" in text:
                undergraduate_type = "985é™¢æ ¡"
            elif "211" in text:
                undergraduate_type = "211é™¢æ ¡"
            elif "æµ·å¤–æœ¬ç§‘" in text:
                undergraduate_type = "æµ·å¤–æœ¬ç§‘"

            # æå–å½•å–æ—¶é—´
            date_match = re.search(r'(\d{4})å¹´(\d{2})æœˆ', text)
            if date_match:
                offer_date = f"{date_match.group(1)}å¹´{date_match.group(2)}æœˆ"
            else:
                offer_date = ""

            return Case(
                university=university,
                major=major,
                student_background=student_background,
                gpa=gpa,
                ielts=ielats,
                toefl=toefl,
                undergraduate_type=undergraduate_type,
                offer_date=offer_date
            )
        except Exception as e:
            print(f"è§£æå¡ç‰‡å¤±è´¥: {e}")
            return None

    async def fetch_cases(self, max_cases: int = 50, scroll_wait: float = 1.0) -> CaseList:
        """æŠ“å–æ¡ˆä¾‹åˆ—è¡¨"""
        case_list = CaseList()

        async with async_playwright() as p:
            self.browser = await p.chromium.launch(headless=self.headless)
            self.page = await self.browser.new_page()

            await self.page.goto(self.BASE_URL, wait_until="networkidle")
            await self.page.wait_for_timeout(2000)  # ç­‰å¾…JSæ¸²æŸ“

            last_height = 0
            scroll_attempts = 0
            max_scroll_attempts = 100  # é˜²æ­¢æ— é™æ»šåŠ¨

            while len(case_list) < max_cases and scroll_attempts < max_scroll_attempts:
                # æ»šåŠ¨åˆ°åº•éƒ¨
                await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await self.page.wait_for_timeout(int(scroll_wait * 1000))

                # è·å–å½“å‰é¡µé¢é«˜åº¦
                current_height = await self.page.evaluate("document.body.scrollHeight")

                # è§£æé¡µé¢ä¸Šçš„æ¡ˆä¾‹å¡ç‰‡
                case_cards = await self.page.query_selector_all(".school-item, .offer-item, .case-item")

                for card in case_cards:
                    if len(case_list) >= max_cases:
                        break

                    case = await self._parse_case_from_card(card)
                    if case:
                        # æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆé€šè¿‡å¤§å­¦+ä¸“ä¸š+GPAåˆ¤æ–­ï¼‰
                        is_duplicate = any(
                            c.university == case.university
                            and c.major == case.major
                            and c.gpa == case.gpa
                            for c in case_list.cases
                        )
                        if not is_duplicate:
                            case_list.add(case)

                # å¦‚æœé¡µé¢é«˜åº¦æ²¡å˜ï¼Œè¯´æ˜åˆ°åº•äº†
                if current_height == last_height:
                    scroll_attempts += 1
                else:
                    scroll_attempts = 0
                    last_height = current_height

        return case_list

    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
```

**Step 4: è¿è¡Œæµ‹è¯•éªŒè¯é€šè¿‡**

```bash
pytest tests/test_scraper.py -v
```
Expected: PASS

**Step 5: æäº¤**

```bash
git add src/scraper.py tests/test_scraper.py
git commit -m "feat: add Playwright-based scraper"
```

---

## Task 4: å®ç°æ•°æ®å­˜å‚¨å’Œå¯¼å‡º

**Files:**
- Create: `compassedu-scraper/src/storage.py`
- Test: `compassedu-scraper/tests/test_storage.py`

**Step 1: ç¼–å†™å¤±è´¥çš„æµ‹è¯•**

```python
# tests/test_storage.py
import os
import json
from src.storage import CaseStorage
from src.models import Case, CaseList

def test_storage_init(tmp_path):
    db_path = tmp_path / "cases.json"
    storage = CaseStorage(db_path=str(db_path))
    assert os.path.exists(db_path)

def test_storage_save_and_load(tmp_path):
    db_path = tmp_path / "cases.json"
    storage = CaseStorage(db_path=str(db_path))

    case_list = CaseList()
    case = Case(
        university="æµ‹è¯•å¤§å­¦",
        major="æµ‹è¯•ä¸“ä¸š",
        student_background="æµ‹è¯•èƒŒæ™¯",
        gpa="3.5",
        undergraduate_type="985é™¢æ ¡",
        offer_date="2026å¹´02æœˆ"
    )
    case_list.add(case)

    storage.save(case_list)

    # é‡æ–°åŠ è½½
    loaded = storage.load()
    assert len(loaded) == 1
    assert loaded[0]["university"] == "æµ‹è¯•å¤§å­¦"

def test_export_csv(tmp_path):
    db_path = tmp_path / "cases.json"
    csv_path = tmp_path / "cases.csv"
    storage = CaseStorage(db_path=str(db_path))

    case_list = CaseList()
    case = Case(
        university="æµ‹è¯•å¤§å­¦",
        major="æµ‹è¯•ä¸“ä¸š",
        student_background="æµ‹è¯•èƒŒæ™¯",
        gpa="3.5",
        ielts="7.0",
        undergraduate_type="985é™¢æ ¡",
        offer_date="2026å¹´02æœˆ"
    )
    case_list.add(case)
    storage.save(case_list)

    storage.export_csv(str(csv_path))
    assert os.path.exists(csv_path)

    # éªŒè¯CSVå†…å®¹
    import pandas as pd
    df = pd.read_csv(csv_path)
    assert len(df) == 1
    assert df.iloc[0]["university"] == "æµ‹è¯•å¤§å­¦"
```

**Step 2: è¿è¡Œæµ‹è¯•éªŒè¯å¤±è´¥**

```bash
pytest tests/test_storage.py -v
```
Expected: FAIL - ModuleNotFoundError

**Step 3: å®ç°å­˜å‚¨é€»è¾‘**

```python
# src/storage.py
import json
import os
import pandas as pd
from typing import List, Dict
from .models import CaseList


class CaseStorage:
    """æ¡ˆä¾‹æ•°æ®å­˜å‚¨"""

    def __init__(self, db_path: str = "data/cases.json"):
        self.db_path = db_path
        self._ensure_dir()

    def _ensure_dir(self):
        """ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨"""
        directory = os.path.dirname(self.db_path)
        if directory and not os.path.exists(directory):
            os.makedirs(directory)

    def load(self) -> List[Dict]:
        """åŠ è½½å·²å­˜å‚¨çš„æ¡ˆä¾‹"""
        if not os.path.exists(self.db_path):
            return []

        with open(self.db_path, "r", encoding="utf-8") as f:
            return json.load(f)

    def save(self, case_list: CaseList) -> None:
        """ä¿å­˜æ¡ˆä¾‹æ•°æ®"""
        existing = self.load()

        # è½¬æ¢æ–°æ¡ˆä¾‹ä¸ºå­—å…¸
        new_cases = case_list.to_dicts()

        # åˆå¹¶å»é‡
        existing_ids = {self._case_id(c) for c in existing}
        for case in new_cases:
            case_id = self._case_id(case)
            if case_id not in existing_ids:
                existing.append(case)

        # ä¿å­˜
        with open(self.db_path, "w", encoding="utf-8") as f:
            json.dump(existing, f, ensure_ascii=False, indent=2)

    def _case_id(self, case: Dict) -> str:
        """ç”Ÿæˆæ¡ˆä¾‹å”¯ä¸€ID"""
        return f"{case['university']}|{case['major']}|{case['gpa']}"

    def export_csv(self, csv_path: str) -> None:
        """å¯¼å‡ºä¸º CSV"""
        data = self.load()
        if not data:
            return

        df = pd.DataFrame(data)
        df.to_csv(csv_path, index=False, encoding="utf-8-sig")
        print(f"å·²å¯¼å‡º {len(df)} æ¡æ¡ˆä¾‹åˆ° {csv_path}")
```

**Step 4: è¿è¡Œæµ‹è¯•éªŒè¯é€šè¿‡**

```bash
pytest tests/test_storage.py -v
```
Expected: PASS

**Step 5: æäº¤**

```bash
git add src/storage.py tests/test_storage.py
git commit -m "feat: add case storage with JSON and CSV export"
```

---

## Task 5: å®ç°å‘½ä»¤è¡Œå…¥å£

**Files:**
- Create: `compassedu-scraper/src/__main__.py`
- Create: `compassedu-scraper/config.py`

**Step 1: åˆ›å»ºé…ç½®æ–‡ä»¶**

```python
# config.py
import os

BASE_URL = "https://m.compassedu.hk/offer/"
DEFAULT_DB_PATH = "data/cases.json"
DEFAULT_CSV_PATH = "data/cases.csv"
DEFAULT_MAX_CASES = 100
HEADLESS = os.getenv("HEADLESS", "true").lower() == "true"
```

**Step 2: åˆ›å»ºä¸»å…¥å£**

```python
# src/__main__.py
import asyncio
import argparse
from .scraper import CompassEduscraper
from .storage import CaseStorage
from . import config


async def main():
    parser = argparse.ArgumentParser(description="æŒ‡å—è€…ç•™å­¦æ¡ˆä¾‹åº“æŠ“å–å·¥å…·")
    parser.add_argument("-n", "--max-cases", type=int, default=config.DEFAULT_MAX_CASES,
                        help="æœ€å¤§æŠ“å–æ¡ˆä¾‹æ•°")
    parser.add_argument("-o", "--output", type=str, default=config.DEFAULT_CSV_PATH,
                        help="CSVè¾“å‡ºè·¯å¾„")
    parser.add_argument("--no-headless", action="store_true",
                        help="æ˜¾ç¤ºæµè§ˆå™¨çª—å£")
    parser.add_argument("--export-only", action="store_true",
                        help="ä»…å¯¼å‡ºå·²æœ‰æ•°æ®ï¼Œä¸æŠ“å–")

    args = parser.parse_args()

    storage = CaseStorage(db_path=config.DEFAULT_DB_PATH)

    if args.export_only:
        print("å¯¼å‡ºå·²æœ‰æ•°æ®...")
    else:
        print(f"å¼€å§‹æŠ“å–æ¡ˆä¾‹ï¼Œç›®æ ‡æ•°é‡: {args.max_cases}")
        scraper = CompassEduscraper(headless=not args.no_headless)
        case_list = await scraper.fetch_cases(max_cases=args.max_cases)
        await scraper.close()

        print(f"æˆåŠŸæŠ“å– {len(case_list)} æ¡æ¡ˆä¾‹")
        storage.save(case_list)

    # å¯¼å‡ºCSV
    storage.export_csv(args.output)
    print("å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
```

**Step 3: æµ‹è¯•è¿è¡Œ**

```bash
cd compassedu-scraper
python -m src --help
```
Expected: æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

**Step 4: æäº¤**

```bash
git add src/__main__.py config.py
git commit -m "feat: add CLI entry point"
```

---

## Task 6: ç¼–å†™ä½¿ç”¨æ–‡æ¡£

**Files:**
- Modify: `compassedu-scraper/README.md`

**Step 1: æ›´æ–° README**

```markdown
# æŒ‡å—è€…ç•™å­¦æ¡ˆä¾‹åº“æŠ“å–å·¥å…·

ä» m.compassedu.hk/offer/ æŠ“å–ç•™å­¦å½•å–æ¡ˆä¾‹æ•°æ®ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ“Š æŠ“å–å®Œæ•´æ¡ˆä¾‹ä¿¡æ¯ï¼ˆå­¦ç”ŸèƒŒæ™¯ã€å½•å–å­¦æ ¡/ä¸“ä¸šã€GPAã€è¯­è¨€æˆç»©ç­‰ï¼‰
- ğŸ”„ å¢é‡æ›´æ–°ï¼ˆè‡ªåŠ¨è·³è¿‡å·²æŠ“å–çš„æ¡ˆä¾‹ï¼‰
- ğŸ“ æ”¯æŒå¯¼å‡ºä¸º JSON/CSV æ ¼å¼
- ğŸ¯ å¯é…ç½®æŠ“å–æ•°é‡

## å®‰è£…

\`\`\`bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£… Playwright æµè§ˆå™¨
playwright install chromium
\`\`\`

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

\`\`\`bash
# æŠ“å–é»˜è®¤æ•°é‡ï¼ˆ100æ¡ï¼‰
python -m src

# æŒ‡å®šæŠ“å–æ•°é‡
python -m src -n 50

# æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼ˆè°ƒè¯•ç”¨ï¼‰
python -m src --no-headless

# ä»…å¯¼å‡ºå·²æœ‰æ•°æ®ï¼Œä¸æŠ“å–
python -m src --export-only

# è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
python -m src -o mydata/cases.csv
\`\`\`

### æ•°æ®å­—æ®µ

æŠ“å–çš„æ•°æ®åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å­—æ®µ | è¯´æ˜ |
|------|------|
| university | å½•å–å­¦æ ¡ |
| major | å½•å–ä¸“ä¸š |
| student_background | å­¦ç”ŸèƒŒæ™¯ï¼ˆæœ¬ç§‘å­¦æ ¡+ä¸“ä¸š+æ¯•ä¸šçŠ¶æ€ï¼‰ |
| gpa | GPAæˆç»© |
| ielts | é›…æ€æˆç»©ï¼ˆå¦‚æœ‰ï¼‰ |
| toefl | æ‰˜ç¦æˆç»©ï¼ˆå¦‚æœ‰ï¼‰ |
| undergraduate_type | æœ¬ç§‘é™¢æ ¡ç±»å‹ï¼ˆ985/211/æ™®é€šæœ¬ç§‘/æµ·å¤–æœ¬ç§‘ï¼‰ |
| offer_date | å½•å–æ—¶é—´ |

## æ•°æ®å­˜å‚¨

- `data/cases.json` - åŸå§‹JSONæ•°æ®ï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰
- `data/cases.csv` - å¯¼å‡ºçš„CSVæ–‡ä»¶

## æµ‹è¯•

\`\`\`bash
pytest tests/ -v
\`\`\`
```

**Step 2: æäº¤**

```bash
git add README.md
git commit -m "docs: update README with usage instructions"
```

---

## Task 7: ç«¯åˆ°ç«¯æµ‹è¯•

**Files:**
- Test: `compassedu-scraper/tests/test_e2e.py`

**Step 1: ç¼–å†™ç«¯åˆ°ç«¯æµ‹è¯•**

```python
# tests/test_e2e.py
import pytest
import os
from src.scraper import CompassEduscraper
from src.storage import CaseStorage

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_full_scrape_workflow(tmp_path):
    """æµ‹è¯•å®Œæ•´çš„æŠ“å–å·¥ä½œæµ"""
    db_path = os.path.join(tmp_path, "test_cases.json")
    csv_path = os.path.join(tmp_path, "test_cases.csv")

    # æŠ“å–å°‘é‡æ¡ˆä¾‹
    scraper = CompassEduscraper(headless=True)
    case_list = await scraper.fetch_cases(max_cases=3)
    await scraper.close()

    assert len(case_list) > 0

    # ä¿å­˜
    storage = CaseStorage(db_path=db_path)
    storage.save(case_list)

    # éªŒè¯ä¿å­˜æˆåŠŸ
    loaded = storage.load()
    assert len(loaded) == len(case_list)

    # å¯¼å‡ºCSV
    storage.export_csv(csv_path)
    assert os.path.exists(csv_path)

    # éªŒè¯CSVå†…å®¹
    import pandas as pd
    df = pd.read_csv(csv_path)
    assert len(df) == len(case_list)
    assert "university" in df.columns
    assert "major" in df.columns
```

**Step 2: è¿è¡Œæµ‹è¯•**

```bash
pytest tests/test_e2e.py -v -m e2e
```
Expected: PASS

**Step 3: æäº¤**

```bash
git add tests/test_e2e.py
git commit -m "test: add end-to-end workflow test"
```

---

## éªŒæ”¶æ ‡å‡†

1. âœ… æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ (`pytest tests/ -v`)
2. âœ… èƒ½æˆåŠŸæŠ“å–è‡³å°‘10æ¡çœŸå®æ¡ˆä¾‹
3. âœ… å¯¼å‡ºçš„CSVæ–‡ä»¶å¯ç”¨Excelæ­£å¸¸æ‰“å¼€
4. âœ… å¢é‡æ›´æ–°åŠŸèƒ½æ­£å¸¸ï¼ˆé‡å¤è¿è¡Œä¸ä¼šäº§ç”Ÿé‡å¤æ•°æ®ï¼‰
